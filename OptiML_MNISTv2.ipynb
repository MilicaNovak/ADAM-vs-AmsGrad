{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptiML_MNIST.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nb49jUQXHpzg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First cell can be skipped if you are not working with: https://colab.research.google.com/"
      ]
    },
    {
      "metadata": {
        "id": "StSLCGlXG2vw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "279026a3-e4ac-4fab-d0eb-5cc0c086345d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526998879690,
          "user_tz": -120,
          "elapsed": 4757,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu90/torch-0.3.1-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.3.1 from http://download.pytorch.org/whl/cu90/torch-0.3.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.1)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (1.14.3)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (3.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KPWyJyGAHNCI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import os\n",
        "\n",
        "from torch import optim\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J8L8debuHPOC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_mnist_model():\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(784, 100),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(100, 10)\n",
        "  )\n",
        "\n",
        "def train_model_sgd(model, train_input, train_target, nb_epochs = 150, mini_batch_size = 100, lr = 1e-1):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr)\n",
        "\n",
        "  for e in range(0, nb_epochs):\n",
        "      for b in range(0, train_input.size(0), mini_batch_size):\n",
        "          output = model(train_input.narrow(0, b, mini_batch_size))\n",
        "          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
        "          model.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "def train_model_adam(model, train_input, train_target, nb_epochs = 150, mini_batch_size = 100, lr = 1e-3, beta1 = 0.9, beta2 = 0.999):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr, betas = (beta1,beta2))\n",
        "\n",
        "  for e in range(0, nb_epochs):\n",
        "      for b in range(0, train_input.size(0), mini_batch_size):\n",
        "          output = model(train_input.narrow(0, b, mini_batch_size))\n",
        "          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
        "          model.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "def train_model_amsgrad(model, train_input, train_target, nb_epochs = 150, mini_batch_size = 100, lr = 1e-3, beta1 = 0.9, beta2 = 0.999):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr, betas = (beta1,beta2), amsgrad = True)\n",
        "\n",
        "  for e in range(0, nb_epochs):\n",
        "      for b in range(0, train_input.size(0), mini_batch_size):\n",
        "          output = model(train_input.narrow(0, b, mini_batch_size))\n",
        "          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
        "          model.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "def compute_prc_errors(model, data_input, data_target, mini_batch_size = 100, test_prc = False):\n",
        "  nb_data_errors = 0\n",
        "  \n",
        "  for b in range(0, data_input.size(0), mini_batch_size):\n",
        "      output = model(data_input.narrow(0, b, mini_batch_size))\n",
        "      _, predicted_classes = torch.max(output.data, 1)\n",
        "      for k in range(0, mini_batch_size):\n",
        "          if data_target.data[b + k] != predicted_classes[k]:\n",
        "              nb_data_errors = nb_data_errors + 1\n",
        "              \n",
        "  # compute error rate for train/test set depending on flag test_prc\n",
        "  if (test_prc):\n",
        "    percentage = nb_data_errors/test_input.size(0) * 100\n",
        "  else:\n",
        "    percentage = nb_data_errors/train_input.size(0) * 100\n",
        "  return percentage\n",
        "\n",
        "def print_errors(mini_batch_size = 100):\n",
        "  train_percent = compute_prc_errors(model, train_input, train_target,  mini_batch_size, test_prc = False)\n",
        "  print('train error = {:0.2f}%'.format(train_percent))\n",
        "  test_percent = compute_prc_errors(model, test_input, test_target, mini_batch_size, test_prc = True)\n",
        "  print('test error = {:0.2f}%'.format(test_percent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DuwpUr0aOmYG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_mnist_model():\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(784, 100),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(100, 10)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5g642XXVn_1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_dataset():\n",
        "  \n",
        "  root = './data'\n",
        "  if not os.path.exists(root):\n",
        "    os.mkdir(root)\n",
        "\n",
        "  mnist_train_set = datasets.MNIST(root = root, train = True, download = True)\n",
        "  mnist_test_set = datasets.MNIST(root = root, train = False, download = True)\n",
        "  return mnist_train_set, mnist_test_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zL4E-clQn9UF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "  \n",
        "  root = './data'\n",
        "  if not os.path.exists(root):\n",
        "    os.mkdir(root)\n",
        "\n",
        "  #trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "  mnist_train_set = datasets.MNIST(root = root, train = True, download = True) #, transform = trans\n",
        "  mnist_test_set = datasets.MNIST(root = root, train = False, download = True) # , transform = trans\n",
        "\n",
        "  train_input = mnist_train_set.train_data.view(mnist_train_set.train_data.size(0),-1).float()\n",
        "  train_target = mnist_train_set.train_labels\n",
        "  test_input = mnist_test_set.test_data.view(mnist_test_set.test_data.size(0),-1).float()\n",
        "  test_target = mnist_test_set.test_labels\n",
        "  \n",
        "  return train_input, train_target, test_input, test_target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPMCm1BSfeOa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the train and test data for MNIST dataset, normalize"
      ]
    },
    {
      "metadata": {
        "id": "JwTLc_4_faq_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_input, train_target, test_input, test_target = get_data()\n",
        "# normalize the data\n",
        "mean, std = train_input.mean(), train_input.std()\n",
        "train_input.sub_(mean).div_(std)\n",
        "test_input.sub_(mean).div_(std)\n",
        "\n",
        "# converting Tensors into Variables before using themin model\n",
        "train_input = Variable(train_input)\n",
        "train_target = Variable(train_target)\n",
        "test_input = Variable(test_input)\n",
        "test_target = Variable(test_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0FsXcz8NtYZy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train_model_kfold_sgd(model, train_dataset, kfold=5, shuffle=True, nb_epochs = 150, mini_batch_size = 100, lr = 1e-1):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr)\n",
        "  \n",
        "  from sklearn.model_selection import KFold\n",
        "  from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "  kf = KFold(n_splits = kfold, shuffle=shuffle)\n",
        "\n",
        "  # Define vectors to store results for each fold\n",
        "  train_loss_fold = []\n",
        "  val_loss_fold = []\n",
        "  train_acc_fold = []\n",
        "  val_acc_fold = []\n",
        "  \n",
        "  for train_index, val_index in kf.split(train_dataset.train_data):       \n",
        "    train_sampler = SubsetRandomSampler(train_index)\n",
        "    val_sampler = SubsetRandomSampler(val_index)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "        batch_size=mini_batch_size, sampler=train_sampler, drop_last=False)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "        batch_size=mini_batch_size, sampler=val_sampler, drop_last=False)\n",
        "\n",
        "    model = create_mnist_model()\n",
        "    if torch.cuda.is_available():\n",
        "      model = model.cuda()\n",
        "      #train_dataset.input, val_dataset.input = train_input.cuda(), train_target.cuda(),test_input.cuda(), test_target.cuda()\n",
        "\n",
        "    # Store loss and accuracy per each epoch\n",
        "    train_e_loss = []\n",
        "    val_e_loss = []\n",
        "    train_e_acc = []\n",
        "    val_e_acc = []\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      criterion = nn.CrossEntropyLoss().cuda()\n",
        "    #optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "    optimizer = optim.SGD(model.parameters(), lr)\n",
        "    \n",
        "    for epoch in range(0, nb_epochs):\n",
        "        # for this epoch calculate train loss, accuracy\n",
        "        train_loss, train_acc = train_model(train_loader, model,\n",
        "            criterion, optimizer)\n",
        "        \n",
        "        # Store them in list to be able to plot\n",
        "        train_e_loss.append(train_loss)\n",
        "        train_e_acc.append(train_acc)\n",
        "\n",
        "        # Evaluate for epoch val loss and accuracy\n",
        "        val_loss, val_acc = validate_model(val_loader, model,\n",
        "            criterion)\n",
        "        \n",
        "        # Store them in the list to be able to plot\n",
        "        val_e_loss.append(val_loss)\n",
        "        val_e_acc.append(val_acc)\n",
        "    \n",
        "    # for k-fold sets, store loss and accuracy through epochs \n",
        "    train_loss_kfold.append(train_e_loss)\n",
        "    val_loss_kfold.append(val_e_loss)\n",
        "    train_acc_kfold.append(train_e_acc)\n",
        "    val_acc_kfold.append(val_e_acc)\n",
        "    \n",
        "  return train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold\n",
        "\n",
        "def train_model(train_loader, model, criterion, optimizer):\n",
        "    # Set model for training\n",
        "    model.train()\n",
        "    \n",
        "    # Initialize counters to 0\n",
        "    nb_correct = 0\n",
        "    nb_elem = 0\n",
        "    loss_epoch = 0\n",
        "    \n",
        "    # Iterate over batches\n",
        "    for i, (train_data, train_labels) in enumerate(train_loader):\n",
        "        # Create Variable\n",
        "        inputs = Variable(train_data)\n",
        "        targets = Variable(train_labels)\n",
        "        if torch.cuda.is_available():\n",
        "          inputs = inputs.cuda()\n",
        "          targets = targets.cuda()\n",
        "\n",
        "        # Clear gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Predicted labels (the one with highest probability)\n",
        "        pred_label = outputs.data.max(1)[1]\n",
        "\n",
        "         # Compute and store the loss\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss_epoch += loss.data[0]\n",
        "        \n",
        "        # Update nb. correct and nb of elem\n",
        "        nb_correct += (pred_label == targets.data).sum()\n",
        "        nb_elem += len(pred_label)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss_epoch /=nb_elem\n",
        "    acc_epoch = nb_correct/nb_elem\n",
        "    return loss_epoch, acc_epoch\n",
        "\n",
        "\n",
        "def validate_model(val_loader, model, criterion):\n",
        "    # Switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize counters\n",
        "    nb_correct = 0\n",
        "    nb_elem = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    # Iterate over batches\n",
        "    for i, (val_data, val_labels) in enumerate(val_loader):\n",
        "        # Create Variable\n",
        "        inputs = Variable(val_data)\n",
        "        targets = Variable(val_labels)\n",
        "        if torch.cuda.is_available():\n",
        "          inputs = inputs.cuda()\n",
        "          targets = targets.cuda()\n",
        "        \n",
        "        # Obtain predictions\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # Predicted label (highest probability)\n",
        "        pred_label = scores.data.max(1)[1]\n",
        "\n",
        "        # Loss\n",
        "        loss = criterion(scores, targets)\n",
        "        loss_epoch += loss.data[0]\n",
        "\n",
        "        # Update nb. correct and nb. total\n",
        "        nb_correct += (pred_label == targets.data).sum()\n",
        "        nb_elem += len(pred_label)\n",
        "        \n",
        "    loss_epoch/=nb_elem\n",
        "    acc_epoch = nb_correct/nb_elem\n",
        "    return test_loss, acc_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A6OqwjikGkbs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function for plotting"
      ]
    },
    {
      "metadata": {
        "id": "UVwguvRBGjbG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "def plot_acc_loss(tr_loss, te_loss, tr_acc, te_acc, title=\"MNIST\"):   \n",
        "    plt.figure()\n",
        "    title=\"MNIST loss\"\n",
        "    sns.tsplot(np.array(tr_loss)).set_title(title)\n",
        "    sns.tsplot(np.array(te_loss), color = 'r')\n",
        "    plt.legend(['Train', 'Validation'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.figure()\n",
        "    title=\"MNIST accuracy\"\n",
        "    sns.tsplot(np.array(tr_acc)).set_title(title)\n",
        "    sns.tsplot(np.array(te_acc), color = 'r')\n",
        "    plt.legend(['Train', 'Validation'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PeydXXFOijmG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model with specific set of parameters, i.e lr=0.1, , it takes so much time, like 2 min GPU ![alt text](https://)"
      ]
    },
    {
      "metadata": {
        "id": "Z4Ul4svnH8Qo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_mnist_model()\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "  train_input, train_target,test_input, test_target= train_input.cuda(), train_target.cuda(),test_input.cuda(), test_target.cuda()\n",
        "nb_epochs = 150\n",
        "mini_batch = 100\n",
        "lr = 1e-1\n",
        "\n",
        "train_model_sgd(model, train_input, train_target, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2WuHVFXisZF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Print error rate on train and test set"
      ]
    },
    {
      "metadata": {
        "id": "JPXW_F54hW53",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a5cec75-d2d2-40a9-f42f-959211ef6e99",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526938968142,
          "user_tz": -120,
          "elapsed": 6233,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# nb_epochs = 150, mini_batch = 100, lr = 1e-1\n",
        "print_errors(mini_batch)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error = 0.00%\n",
            "test error = 1.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WFGCv7jri9v0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train with new learning rates"
      ]
    },
    {
      "metadata": {
        "id": "AVCNbO0FVfd9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cb1c552d-69b0-4c9e-d603-7a48b1104210",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526939102056,
          "user_tz": -120,
          "elapsed": 129321,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# nb_epochs = 150, mini_batch = 100, lr = 1e-2\n",
        "lr = 1e-2\n",
        "train_model_sgd(model, train_input, train_target, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = lr)\n",
        "print_errors(mini_batch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error = 0.00%\n",
            "test error = 1.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7qaVzYnDe5eW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc6fe1cb-ff27-454a-a9ea-331c90267645",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526939282742,
          "user_tz": -120,
          "elapsed": 131282,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# nb_epochs = 150, mini_batch = 100, lr = 0.5\n",
        "lr = 1e-3\n",
        "train_model_sgd(model, train_input, train_target, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = lr)\n",
        "print_errors(mini_batch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error = 0.00%\n",
            "test error = 1.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qgt3NNI7gCX7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "25a88dab-9a29-4889-8775-1ecc8a10b860",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526939472701,
          "user_tz": -120,
          "elapsed": 131375,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# nb_epochs = 150, mini_batch = 100, lr = 0.5\n",
        "lr = 1e-6\n",
        "train_model_sgd(model, train_input, train_target, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = lr)\n",
        "print_errors(mini_batch)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error = 0.00%\n",
            "test error = 1.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9xGaXadJw1qP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e0022437-84f5-4b61-e3b6-cc3d879e2172",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526940930130,
          "user_tz": -120,
          "elapsed": 131359,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# nb_epochs = 150, mini_batch = 100, lr = 0.5\n",
        "lr = 1\n",
        "train_model_sgd(model, train_input, train_target, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = lr)\n",
        "print_errors(mini_batch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error = 23.65%\n",
            "test error = 25.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oN61EvyPw47Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "05a2d101-e8e8-4c4e-9090-7ad989aeaea8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526941137572,
          "user_tz": -120,
          "elapsed": 131536,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# nb_epochs = 150, mini_batch = 100, lr = 0.5\n",
        "lr = 0.5\n",
        "train_model_sgd(model, train_input, train_target, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = lr)\n",
        "print_errors(mini_batch)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error = 4.61%\n",
            "test error = 7.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R9fHtY6IH4HT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "c4f02d63-41d1-46f5-926c-c33f52762ac2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526998216350,
          "user_tz": -120,
          "elapsed": 703,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = get_dataset()\n",
        "#print(train_dataset.train_data)\n",
        "print(train_dataset.train_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchvision.datasets.mnist.MNIST'>\n",
            "\n",
            " 5\n",
            " 0\n",
            " 4\n",
            "⋮ \n",
            " 5\n",
            " 6\n",
            " 8\n",
            "[torch.LongTensor of size 60000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "93vdDXIRNxsQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "3199fe0b-2516-4fb9-9ac0-1df382eb7eb7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526998715345,
          "user_tz": -120,
          "elapsed": 725,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_dataset.test_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 7\n",
            " 2\n",
            " 1\n",
            "⋮ \n",
            " 4\n",
            " 5\n",
            " 6\n",
            "[torch.LongTensor of size 10000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l5jUbt8RN3u2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Normalizing data"
      ]
    },
    {
      "metadata": {
        "id": "ibH5hE-bM3zs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "2137049c-fd84-4a86-cf86-9341138d12f9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526998980301,
          "user_tz": -120,
          "elapsed": 1453,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = get_dataset()\n",
        "train_dataset.train_data = train_dataset.train_data.view(train_dataset.train_data.size(0),-1).float()\n",
        "test_dataset.test_data = test_dataset.test_data.view(test_dataset.test_data.size(0),-1).float()\n",
        "\n",
        "mean, std = train_dataset.train_data.mean(), train_dataset.train_data.std()\n",
        "train_dataset.train_data.sub_(mean).div_(std)\n",
        "test_dataset.test_data.sub_(mean).div_(std)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "-0.4241 -0.4241 -0.4241  ...  -0.4241 -0.4241 -0.4241\n",
              "-0.4241 -0.4241 -0.4241  ...  -0.4241 -0.4241 -0.4241\n",
              "-0.4241 -0.4241 -0.4241  ...  -0.4241 -0.4241 -0.4241\n",
              "          ...             ⋱             ...          \n",
              "-0.4241 -0.4241 -0.4241  ...  -0.4241 -0.4241 -0.4241\n",
              "-0.4241 -0.4241 -0.4241  ...  -0.4241 -0.4241 -0.4241\n",
              "-0.4241 -0.4241 -0.4241  ...  -0.4241 -0.4241 -0.4241\n",
              "[torch.FloatTensor of size 10000x784]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "yTvDV0BqxriD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "outputId": "9ca73954-ae42-4a98-ed6e-0708c417c757",
        "executionInfo": {
          "status": "error",
          "timestamp": 1526999055043,
          "user_tz": -120,
          "elapsed": 705,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_mnist_model()\n",
        "nb_epochs = 150\n",
        "lr = 1e-1\n",
        "mini_batch = 100\n",
        "\n",
        "train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold = train_model_kfold_sgd(model, train_dataset, kfold=5, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, lr = 1e-1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-508de0dd36d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loss_kfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_kfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_kfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_kfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_kfold_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-a2968ad74e21>\u001b[0m in \u001b[0;36mtrain_model_kfold_sgd\u001b[0;34m(model, train_dataset, kfold, shuffle, nb_epochs, mini_batch_size, lr)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# for this epoch calculate train loss, accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         train_loss, train_acc = train_model(train_loader, model,\n\u001b[0;32m---> 45\u001b[0;31m             criterion, optimizer)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Store them in list to be able to plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a2968ad74e21>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Iterate over batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Create Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2441\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many dimensions: %d > %d.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2443\u001b[0;31m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tobytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "J2aecCOaN8HG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting functions"
      ]
    },
    {
      "metadata": {
        "id": "TnjXT-LCN7cl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "d3c81fb8-1ec1-46a8-f791-3b55a61bbecc",
        "executionInfo": {
          "status": "error",
          "timestamp": 1526998753148,
          "user_tz": -120,
          "elapsed": 967,
          "user": {
            "displayName": "Milica Novakovic",
            "photoUrl": "//lh6.googleusercontent.com/-PdM9ODluhz0/AAAAAAAAAAI/AAAAAAAAABc/XV0m45-1Nmw/s50-c-k-no/photo.jpg",
            "userId": "110546638424582068159"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plot_acc_loss(train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-46e0c4b3d4c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_acc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tr_loss' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "joqT6RqEN9tC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}