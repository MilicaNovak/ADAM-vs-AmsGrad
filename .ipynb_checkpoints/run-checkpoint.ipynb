{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 23 18:16:08 2018\n",
    "\n",
    "@author: Bob\n",
    "\"\"\"\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from visualizing import plot_acc_loss\n",
    "from models import create_1layer_model, create_convex_model, get_datasets\n",
    "from training_and_validating import train_validate_kfold, train_test\n",
    "from sweeps import grid_search_lr, grid_search_beta\n",
    "\n",
    "\n",
    "### SIMPLE SGD ONE_LAYER\n",
    "\"\"\"\n",
    "model = create_1layer_model()\n",
    "kfold = 5 \n",
    "nb_epochs = 40\n",
    "lr = 1e-1\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = True\n",
    "\n",
    "optimizer_ = optim.SGD\n",
    "opt_parameters_SGD = [lr]\n",
    "\n",
    "train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold = train_validate_kfold(\\\n",
    "        model, optimizer_, opt_parameters_SGD, train_dataset, kfold=kfold, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates)\n",
    "\n",
    "plot_acc_loss(train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold)\n",
    "\n",
    "save_array = [train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold]\n",
    "np.save(os.path.join('../array_and_figures','1st_kf=5_epo=40_lr=1e-1_btch=100_SGD_inter'),save_array)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### GRID SEARCH BETAS ADAM ONE_LAYER\n",
    "\"\"\"\n",
    "#grid_search_beta()\n",
    "res = np.load(os.path.join('../array_and_figures','grid_kf=5_epo=40_lr=1e-3_btch=100_Adam_beta1_beta2.npy'))\n",
    "res = dict(res.tolist())\n",
    "beta1_list = [0.88, 0.89, 0.9, 0.91, 0.92]\n",
    "beta2_list = [0.986, 0.99, 0.994, 0.998, 0.999, 0.9999]\n",
    "num_b1 = len(beta1_list)\n",
    "num_b2 = len(beta2_list)\n",
    "\n",
    "val_acc = np.reshape(np.mean(res['val_acc'], axis=1),(num_b1,num_b2))\n",
    "##correcting mistake in beta1_list\n",
    "tmp = val_acc[2].copy()\n",
    "val_acc[2] = val_acc[3]\n",
    "val_acc[3] = tmp\n",
    "\n",
    "sns.heatmap(val_acc, xticklabels=np.reshape(np.array(beta2_list),(-1,1)), yticklabels=np.reshape(np.array(beta1_list),(-1,1))).set_title('Validating accuracy mean')\n",
    "plt.figure()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### 'GRID' SEARCH LR ADAM ONE_LAYER\n",
    "\"\"\"\n",
    "grid_search_lr()\n",
    "res = np.load(os.path.join('../array_and_figures','grid_kf=4_epo=120_b1=0.91_b2=0.999_btch=100_Adam_lr.npy'))\n",
    "res = dict(res.tolist())\n",
    "lr_list = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "num_lr = len(lr_list)\n",
    "val_acc = np.reshape(np.mean(res['val_acc'], axis=1))\n",
    "sns.heatmap(val_acc, xticklabels=np.reshape(np.array(lr_list),(-1,1)), yticklabels=np.reshape(np.array(lr_list),(-1,1))).set_title('Validating accuracy mean')\n",
    "plt.figure()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "### SIMPLE ADAM ONE_LAYER\n",
    "\"\"\"\n",
    "model = create_1layer_model()\n",
    "kfold = 4\n",
    "nb_epochs = 40\n",
    "lr = 1e-3\n",
    "beta1, beta2 = 0.91, 0.999\n",
    "amsgrad = False\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = True\n",
    "\n",
    "optimizer_ = optim.Adam\n",
    "opt_parameters_Adam = [lr, (beta1, beta2), amsgrad]\n",
    "\n",
    "train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold = train_validate_kfold(\\\n",
    "        model, optimizer_, opt_parameters_Adam, train_dataset, kfold=kfold, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates)\n",
    "\n",
    "plot_acc_loss(train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold)\n",
    "\n",
    "save_array = [train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold]\n",
    "np.save(os.path.join('../array_and_figures','2nd_kf=4_epo=40_lr=1e-3_btch=100_Adam_inter'),save_array)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### Improved ADAM: AMSGRAD ONE_LAYER\n",
    "\"\"\"\n",
    "model = create_1layer_model()\n",
    "kfold = 4\n",
    "nb_epochs = 40\n",
    "lr = 1e-3\n",
    "beta1, beta2 = 0.91, 0.999\n",
    "amsgrad = True\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = True\n",
    "\n",
    "optimizer_ = optim.Adam\n",
    "opt_parameters_Adam = [lr, (beta1, beta2), amsgrad]\n",
    "\n",
    "train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold = train_validate_kfold(\\\n",
    "        model, optimizer_, opt_parameters_Adam, train_dataset, kfold=kfold, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates)\n",
    "\n",
    "plot_acc_loss(train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold)\n",
    "\n",
    "save_array = [train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold]\n",
    "np.save(os.path.join('../array_and_figures','3rd_kf=4_epo=40_lr=1e-3_btch=100_AMSGRAD_inter'),save_array)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### SGD TESTING ONE_LAYER\n",
    "\"\"\"\n",
    "model = create_1layer_model()\n",
    "nb_epochs = 40\n",
    "lr = 1e-1\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = False\n",
    "\n",
    "optimizer_ = optim.SGD\n",
    "opt_parameters_SGD = [lr]\n",
    "\n",
    "\n",
    "train_loss, test_loss, train_acc, test_acc = train_test(\\\n",
    "        model, optimizer_, opt_parameters_SGD, train_dataset, test_dataset, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates)\n",
    "\n",
    "\n",
    "#plot_acc_loss(train_loss, test_loss, train_acc, test_acc)\n",
    "print('SGD test accuracy: {}'.format(test_acc))\n",
    "\n",
    "save_array = [train_loss, test_loss, train_acc, test_acc]\n",
    "np.save(os.path.join('../array_and_figures','4th_epo=40_lr=1e-1_btch=100_SGD_inter_testing'),save_array)\n",
    "\"\"\"\n",
    "\n",
    "### ADAM TESTING ONE_LAYER\n",
    "\"\"\"\n",
    "model = create_1layer_model()\n",
    "nb_epochs = 40\n",
    "lr = 1e-3\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = False\n",
    "\n",
    "\n",
    "beta1, beta2 = 0.91, 0.999\n",
    "amsgrad = False\n",
    "optimizer_ = optim.Adam\n",
    "opt_parameters_Adam = [lr, (beta1, beta2), amsgrad]\n",
    "\n",
    "train_loss, test_loss, train_acc, test_acc = train_test(\\\n",
    "        model, optimizer_, opt_parameters_Adam, train_dataset, test_dataset, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates)\n",
    "\n",
    "\n",
    "#plot_acc_loss(train_loss, test_loss, train_acc, test_acc)\n",
    "print('ADAM test accuracy: {}'.format(test_acc))\n",
    "\n",
    "save_array = [train_loss, test_loss, train_acc, test_acc]\n",
    "np.save(os.path.join('../array_and_figures','5th_epo=40_lr=1e-3_btch=100_Adam_inter_testing'),save_array)\n",
    "\"\"\"\n",
    "### AMSGRAD TESTING ONE_LAYER\n",
    "\n",
    "\"\"\"\n",
    "model = create_1layer_model()\n",
    "nb_epochs = 40\n",
    "lr = 1e-3\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = False\n",
    "\n",
    "\n",
    "beta1, beta2 = 0.91, 0.999\n",
    "amsgrad = True\n",
    "optimizer_ = optim.Adam\n",
    "opt_parameters_Adam = [lr, (beta1, beta2), amsgrad]\n",
    "\n",
    "train_loss, test_loss, train_acc, test_acc = train_test(\\\n",
    "        model, optimizer_, opt_parameters_Adam, train_dataset, test_dataset, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates)\n",
    "\n",
    "\n",
    "#plot_acc_loss(train_loss, test_loss, train_acc, test_acc)\n",
    "print('ADAM test accuracy: {}'.format(test_acc))\n",
    "\n",
    "save_array = [train_loss, test_loss, train_acc, test_acc]\n",
    "np.save(os.path.join('../array_and_figures','6th_epo=40_lr=1e-3_btch=100_AMSGRAD_inter_testing'),save_array)\n",
    "\"\"\"\n",
    "\n",
    "### SIMPLE SGD CONVEX ASODKSAODJASKODJAS\n",
    "\n",
    "\"\"\"\n",
    "model = create_convex_model\n",
    "kfold = 5 \n",
    "nb_epochs = 40\n",
    "lr = 1e-1\n",
    "mini_batch = 100\n",
    "train_dataset, train_loader, test_dataset, test_loader = get_datasets(mini_batch_size = mini_batch)\n",
    "interstates = True\n",
    "run_once = True\n",
    "\n",
    "optimizer_ = optim.SGD\n",
    "opt_parameters_SGD = [lr]\n",
    "\n",
    "train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold = train_validate_kfold(\\\n",
    "        model, optimizer_, opt_parameters_SGD, train_dataset, kfold=kfold, shuffle=True, nb_epochs = nb_epochs, mini_batch_size = mini_batch, interstates = interstates, run_once = run_once)\n",
    "\n",
    "plot_acc_loss(train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold)\n",
    "\n",
    "save_array = [train_loss_kfold, val_loss_kfold, train_acc_kfold, val_acc_kfold]\n",
    "np.save(os.path.join('../array_and_figures','1st_kf=5_epo=40_lr=1e-1_btch=100_SGD_inter_ro_convex'),save_array)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 'GRID' SEARCH LR ADAM CONVEX\n",
    "model = create_convex_model\n",
    "\n",
    "grid_search_lr(model)\n",
    "res = np.load(os.path.join('../array_and_figures','grid_kf=5_epo=120_b1=0.91_b2=0.999_btch=100_Adam_lr_ro_convex.npy'))\n",
    "res = dict(res.tolist())\n",
    "lr_list = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "num_lr = len(lr_list)\n",
    "val_acc = res['val_acc']\n",
    "sns.heatmap(val_acc, xticklabels=np.reshape(np.array(lr_list),(-1,1)), yticklabels=np.reshape(np.array(lr_list),(-1,1))).set_title('Validating accuracy mean')\n",
    "plt.figure()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
